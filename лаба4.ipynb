{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "лаба4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOymcSqAJkqjD6/eKNuqxs5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dunyashina/ohwowitsrepository/blob/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5-%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%8B/%D0%BB%D0%B0%D0%B1%D0%B04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eqd4Rjw4clW"
      },
      "source": [
        "# Задание 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpuJJzN0fjI6"
      },
      "source": [
        "# Задание 1 реализовать SGD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgV2EdHWqdzv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8, batch_size=1):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов \n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        l, d = X.shape\n",
        "\n",
        "        if self.w0 is None: # если нет начальной инициализации весов\n",
        "            self.w0 = np.zeros(d)\n",
        "\n",
        "        self.w = self.w0\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "            self.w_history.append(self.w)\n",
        "\n",
        "            w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "\n",
        "            if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "                break\n",
        "          \n",
        "            self.w = w_new\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        \n",
        "        l, d = X.shape\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        for i in range(l):\n",
        "            y_pred.append(np.dot(X[i], self.w))\n",
        "\n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \n",
        "        l, d = X.shape\n",
        "        gradient = []\n",
        "        \n",
        "        for j in range(d):\n",
        "            dQ = 0\n",
        "            for i in range(l):\n",
        "                dQ += (2/l) * X[i][j] * (np.dot(X[i], self.w) - y[i])\n",
        "            gradient.append(dQ)\n",
        "\n",
        "        return np.array(gradient)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKuR90AfspQm"
      },
      "source": [
        ""
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyoLkl_qgmZ"
      },
      "source": [
        "def plot_gd(X, y, w_history):\n",
        "    # compute level set\n",
        "    A, B = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "\n",
        "    levels = np.empty_like(A)\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(A.shape[1]):\n",
        "            w_tmp = np.array([A[i, j], B[i, j]])\n",
        "            levels[i, j] = np.mean(np.power(np.dot(X, w_tmp) - y, 2))\n",
        "\n",
        "    plt.figure(figsize=(13, 9))\n",
        "    plt.title('GD trajectory')\n",
        "    plt.xlabel(r'$w_1$')\n",
        "    plt.ylabel(r'$w_2$')\n",
        "    plt.xlim((-2.1, 2.1))\n",
        "    plt.ylim((-2.1, 2.1))\n",
        "\n",
        "    # visualize the level set\n",
        "    CS = plt.contour(A, B, levels, levels=np.logspace(0, 2, num=10), cmap=plt.cm.rainbow_r)\n",
        "    CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
        "\n",
        "    # visualize trajectory\n",
        "    w_list = np.array(lr.w_history)\n",
        "    plt.scatter(w_true[0], w_true[1], c='r', marker='*')\n",
        "    plt.scatter(w_list[:, 0], w_list[:, 1])\n",
        "    plt.plot(w_list[:, 0], w_list[:, 1])\n",
        "    plt.show()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxaTA6mFqoJ_"
      },
      "source": [
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8, batch_size=10):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов \n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        ## На каждом шаге градиентного спуска веса можно добавлять в w_history (для последующей отрисовки)\n",
        "        ## Для выполнения шага выберите 10 случайных(равномерно) сэмплов\n",
        "\n",
        "\n",
        "        l, d = X.shape\n",
        "\n",
        "        if self.w0 is None: # если нет начальной инициализации весов\n",
        "            self.w0 = np.zeros(d)\n",
        "\n",
        "        self.w = self.w0\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "           \n",
        "\n",
        "            if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "                break\n",
        "          \n",
        "            self.w = w_new\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        \n",
        "        l, d = X.shape\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        for i in range(l):\n",
        "            y_pred.append(np.dot(X[i], self.w))\n",
        "\n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "\n",
        "        l, d = X.shape\n",
        "        gradient = []\n",
        "        \n",
        "        for j in range(d):\n",
        "            dQ = 0\n",
        "            for i in range(l):\n",
        "                dQ += (2/l) * X[i][j] * (np.dot(X[i], self.w) - y[i])\n",
        "            gradient.append(dQ)\n",
        "\n",
        "        return np.array(gradient)\n",
        "\n",
        "  "
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfJ-cnTjq2Gt"
      },
      "source": [
        "n_features = 2\n",
        "n_objects = 300\n",
        "num_steps = 100\n",
        "\n",
        "\n",
        "np.random.seed(1)\n",
        "w_true = np.random.normal(0, 0.1, size=(n_features, ))\n",
        "w_0 = np.random.uniform(-2, 2, (n_features))\n",
        "\n",
        "X = np.random.uniform(-5, 5, (n_objects, n_features))\n",
        "y = np.dot(X, w_true) + np.random.normal(0, 1, (n_objects))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "r7119X5Aq5Jq",
        "outputId": "ab16be97-4aac-47f1-bea1-4ab015765766"
      },
      "source": [
        "lr = LinearRegressionSGD(w0=w_0, alpha=0.05)\n",
        "lr.fit(X, y)\n",
        "\n",
        "plot_gd(X, y, lr.w_history)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-015b7619d88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegressionSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-7d0762866905>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'w_new' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdZ3TXlmflgY"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_boston()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "DataNums = len(x_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.3, random_state=10)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5pZK1k0fqWB"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}